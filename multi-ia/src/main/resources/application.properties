spring.application.name=vamu-rec-rag

langchain4j.http.client.factory=jdk

# DeepSeek Configuration (usa OpenAI-compatible API)
langchain4j.open-ai.deepseek.streaming-chat-model.api-key=
langchain4j.open-ai.deepseek.streaming-chat-model.base-url=https://api.deepseek.com
langchain4j.open-ai.deepseek.streaming-chat-model.model-name=deepseek-chat

# Gemini Configuration
langchain4j.google-ai-gemini.streaming-chat-model.api-key=
langchain4j.google-ai-gemini.streaming-chat-model.model-name=gemini-2.5-pro

# Ollama Configuration
langchain4j.ollama.streaming-chat-model.base-url=http://localhost:11434
langchain4j.ollama.streaming-chat-model.model-name=llama3.1:8b

logging.level.com.vamu_rec_rag.demo.MultiAiService=DEBUG
logging.level.dev.langchain4j=INFO