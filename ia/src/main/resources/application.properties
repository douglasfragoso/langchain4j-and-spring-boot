spring.application.name=ia

# Configuração LangChain4j Ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=llama3.1:8b
langchain4j.ollama.chat-model.temperature=0.7
langchain4j.ollama.chat-model.timeout=300s

# langchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}
# langchain4j.open-ai.chat-model.model-name=gpt-4o
# langchain4j.open-ai.chat-model.log-requests=true
# langchain4j.open-ai.chat-model.log-responses=true

