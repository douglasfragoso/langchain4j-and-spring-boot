spring.profiles.active=${APP_PROFILE:}
spring.application.name=ia

server.port=8080


langchain4j.http.client=jdk

# Configuration LangChain4j Ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=llama3.1:8b
langchain4j.ollama.chat-model.temperature=0.7
langchain4j.ollama.chat-model.timeout=300s

# Configuration DeepSeek (compat√≠vel com OpenAI API)
langchain4j.deepseek.chat-model.base-url=https://api.deepseek.com/v1
langchain4j.deepseek.chat-model.api-key=
langchain4j.deepseek.chat-model.model-name=deepseek-chat
langchain4j.deepseek.chat-model.temperature=0.7
langchain4j.deepseek.chat-model.timeout=300s
langchain4j.deepseek.chat-model.log-requests=true
langchain4j.deepseek.chat-model.log-responses=true

# Configuration Gemini (Google AI nativo)
langchain4j.gemini.chat-model.api-key=
langchain4j.gemini.chat-model.model-name=gemini-2.5-pro
langchain4j.gemini.chat-model.temperature=0.7
langchain4j.gemini.chat-model.timeout=300s
langchain4j.gemini.chat-model.log-requests=true
langchain4j.gemini.chat-model.log-responses=true

