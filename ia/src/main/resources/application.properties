spring.application.name=ia

# Configuração LangChain4j Ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=llama2
langchain4j.ollama.chat-model.timeout=120s
langchain4j.ollama.chat-model.temperature=0.3
langchain4j.ollama.chat-model.max-tokens=4096
langchain4j.ollama.chat-model.top-p=0.9
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true
langchain4j.ollama.chat-model.log-stream=true

# langchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}
# langchain4j.open-ai.chat-model.model-name=gpt-4o
# langchain4j.open-ai.chat-model.log-requests=true
# langchain4j.open-ai.chat-model.log-responses=true

